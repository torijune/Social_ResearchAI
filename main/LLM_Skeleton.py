from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, SequentialChain
from langchain_community.chat_models import ChatOllama
from textwrap import dedent

from src.table_linearlization import linearize_row_wise
from src.table_parser import load_survey_tables
from src.table_numeric_analysis import main as numeric_analysis


def get_user_selected_table(file_path):
    tables, question_texts, question_keys = load_survey_tables(file_path)

    print("Question key and texts list:")
    for i, key in enumerate(question_keys):
        print(f"{i+1}. [{key}] {question_texts[key]}")

    user_input = input("\nìš”ì•½ì„ ìƒì„±í•  ì§ˆë¬¸ ë²ˆí˜¸(ì˜ˆ: 1) ë˜ëŠ” ì§ˆë¬¸ í‚¤(ì˜ˆ: A1, B14_2)ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()

    if user_input.isdigit():
        choice = int(user_input) - 1
        if choice < 0 or choice >= len(question_keys):
            raise ValueError("ì˜¬ë°”ë¥¸ ì§ˆë¬¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        selected_key = question_keys[choice]
    elif user_input in question_keys:
        selected_key = user_input
    else:
        raise ValueError("ì…ë ¥í•œ ê°’ì´ ì˜¬ë°”ë¥¸ ì§ˆë¬¸ ë²ˆí˜¸ ë˜ëŠ” í‚¤ê°€ ì•„ë‹™ë‹ˆë‹¤.")

    return tables[selected_key], question_texts[selected_key], selected_key


def get_skeleton_template():
    return PromptTemplate(
        input_variables=["linearized_table"],
        template=dedent("""
        ë‹¹ì‹ ì€ í†µê³„ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì„¤ë¬¸ì¡°ì‚¬ í‘œ ë°ì´í„°ë¥¼ ë³´ê³  ìš”ì•½ì— ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•  í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        ğŸ“Š [í‘œ ë°ì´í„°]
        {linearized_table}

        ë‹¤ìŒ ì¡°ê±´ì— ë”°ë¼ 3~6ê°œì˜ í•µì‹¬ ìš”ì ì„ ë¬¸ì¥ìœ¼ë¡œ ë‚˜ì—´í•˜ì„¸ìš”:
        - í‰ê· , ê·¹ë‹¨ê°’, ì§‘ë‹¨ ê°„ ì°¨ì´, í‘œì¤€í¸ì°¨ê°€ í° í•­ëª©
        - ìš”ì•½ì— ë°˜ë“œì‹œ ë“¤ì–´ê°€ì•¼ í•  ìˆ˜ì¹˜ ê¸°ë°˜ ì •ë³´

        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
        - 60ëŒ€ëŠ” í‰ê·  4.1ë¡œ ê°€ì¥ ë†’ì€ ê´€ì‹¬ë„ë¥¼ ë³´ì„
        - ì‹¤ì™¸ ì²´ë¥˜ìëŠ” 'ë§¤ìš° ê´€ì‹¬ ìˆë‹¤' ë¹„ìœ¨ì´ 25.9%ë¡œ ê°€ì¥ ë†’ìŒ
        - ê¸°ì €ì§ˆí™˜ì ë³´ìœ  ì—¬ë¶€ì— ë”°ë¼ 'ê´€ì‹¬ ìˆë‹¤' ë¹„ìœ¨ì´ 11% ì°¨ì´ë‚¨
        """)
    )


def get_summary_template():
    return PromptTemplate(
        input_variables=["linearized_table", "skeleton", "analysis_results"],
        template=dedent("""
        ë‹¹ì‹ ì€ ê°ê´€ì ì¸ í†µê³„ ê¸°ë°˜ ìš”ì•½ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ëŠ” ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„°ë¥¼ ì •ë¦¬í•œ í‘œì´ë©°, ê° í–‰ì€ ì¸êµ¬ì§‘ë‹¨(ì˜ˆ: ì„±ë³„, ì—°ë ¹ëŒ€), ê° ì—´ì€ í•´ë‹¹ ì§‘ë‹¨ì˜ ì‘ë‹µ í†µê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

        ğŸ“Š [í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ)]
        {linearized_table}

        ğŸ“ˆ [ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (ëŒ€ë¶„ë¥˜ë³„ í•­ëª©ë³„ max/min ë° ë¶„ì‚° ë“±)]
        {analysis_results}

        ğŸ“ [ì°¸ê³ ìš© ìŠ¤ì¼ˆë ˆí†¤ ìš”ì ë“¤]
        ë‹¤ìŒì€ í†µê³„ì ìœ¼ë¡œ ì£¼ëª©í•  ë§Œí•œ ì‘ë‹µ ê²½í–¥ì„ ìš”ì•½í•œ ì˜ˆì‹œì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í¬í•¨í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, ìš”ì•½ ì‘ì„±ì— ì°¸ê³ í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.
        {skeleton}

        ğŸ§  Chain of Thought ì¶”ë¡  ìˆœì„œ:
        1. í‘œì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” íŒ¨í„´ì„ ì‹ë³„í•©ë‹ˆë‹¤.
        2. í‰ê· , ê·¹ë‹¨ê°’, í‘œì¤€í¸ì°¨ ë“± ìˆ˜ì¹˜ ê¸°ë°˜ì˜ ì°¨ì´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤.
        3. ì°¸ê³  ìš”ì ê³¼ ë¹„êµí•˜ì—¬ ëˆ„ë½ëœ ì¤‘ìš”í•œ í†µê³„ì  íŠ¹ì§•ì´ ìˆë‹¤ë©´ ë°˜ì˜í•©ë‹ˆë‹¤.

        ğŸ“ ì‘ì„± ì¡°ê±´:
        - ë°˜ë“œì‹œ ìˆ˜ì¹˜ ê¸°ë°˜ ê·¼ê±°ë§Œì„ ë°”íƒ•ìœ¼ë¡œ í•´ì„í•˜ë©°, ì™¸ë¶€ ë°°ê²½ì§€ì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
        - ëª¨ë“  ì†Œë¶„ë¥˜ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ˆì„¸ìš”. ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì´ëŠ” í•­ëª© ìœ„ì£¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        - ë¬¸ì¥ì€ **ê°ê´€ì ì´ê³  ëª…í™•í•˜ê²Œ**, **ì„œìˆ í˜• ë¬¸ë‹¨ 1~2ê°œ**ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
        - ì œëª©ì€ ì“°ì§€ ë§ˆì‹œê³ , ìš”ì•½ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        """)
    )


def run_summary_pipeline(table, linearized_table, analysis_results, model_name="llama-3.1-8B-instrcut:latest"):
    llm = ChatOllama(model=model_name, temperature=0.3)

    skeleton_chain = LLMChain(llm=llm, prompt=get_skeleton_template(), output_key="skeleton")
    summary_chain = LLMChain(llm=llm, prompt=get_summary_template(), output_key="summary")

    full_chain = SequentialChain(
        chains=[skeleton_chain, summary_chain],
        input_variables=["linearized_table", "analysis_results"],
        output_variables=["skeleton", "summary"],
        verbose=True
    )

    return full_chain.invoke({
        "linearized_table": linearized_table,
        "analysis_results": analysis_results
    })


def main():
    file_path = "í†µê³„í‘œ_ìˆ˜ì •_ì„œìš¸ì‹œ ëŒ€ê¸°í™˜ê²½ ì‹œë¯¼ì¸ì‹ ì¡°ì‚¬_250421(ì‘ì—…ìš©).xlsx"

    table, question_text, key = get_user_selected_table(file_path)
    linearized = linearize_row_wise(table)
    analysis = numeric_analysis(table)

    result = run_summary_pipeline(table, linearized, analysis)

    print("\nğŸ”‘ [ìŠ¤ì¼ˆë ˆí†¤ ìš”ì ]")
    print(result["skeleton"])
    print("-" * 20)

    print("\nğŸ”‘ [ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼]")
    print(analysis)
    print("-" * 20)

    print(f"\nğŸ“ [ìµœì¢… ìš”ì•½ for {key}]")
    print(result["summary"])


if __name__ == "__main__":
    main()