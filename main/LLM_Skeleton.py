from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, SequentialChain
from langchain_community.chat_models import ChatOllama
from langchain_openai import ChatOpenAI
from textwrap import dedent

from src.table_linearlization import linearize_row_wise
from src.table_parser import load_survey_tables
from src.table_numeric_analysis import main as numeric_analysis


def get_user_selected_table(file_path):
    tables, question_texts, question_keys = load_survey_tables(file_path)

    print("Question key and texts list:")
    for i, key in enumerate(question_keys):
        print(f"{i+1}. [{key}] {question_texts[key]}")

    user_input = input("\nìš”ì•½ì„ ìƒì„±í•  ì§ˆë¬¸ ë²ˆí˜¸(ì˜ˆ: 1) ë˜ëŠ” ì§ˆë¬¸ í‚¤(ì˜ˆ: A1, B14_2)ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()

    if user_input.isdigit():
        choice = int(user_input) - 1
        if choice < 0 or choice >= len(question_keys):
            raise ValueError("ì˜¬ë°”ë¥¸ ì§ˆë¬¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        selected_key = question_keys[choice]
    elif user_input in question_keys:
        selected_key = user_input
    else:
        raise ValueError("ì…ë ¥í•œ ê°’ì´ ì˜¬ë°”ë¥¸ ì§ˆë¬¸ ë²ˆí˜¸ ë˜ëŠ” í‚¤ê°€ ì•„ë‹™ë‹ˆë‹¤.")

    return tables[selected_key], question_texts[selected_key], selected_key


def get_skeleton_template():
    return PromptTemplate(
        input_variables=["linearized_table"],
        template=dedent("""
        ë‹¹ì‹ ì€ í†µê³„ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì„¤ë¬¸ì¡°ì‚¬ í‘œ ë°ì´í„°ë¥¼ ë³´ê³  ìš”ì•½ì— ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•  í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        ğŸ“Š [í‘œ ë°ì´í„°]
        {linearized_table}

        ë‹¤ìŒ ì¡°ê±´ì— ë”°ë¼ 3~6ê°œì˜ í•µì‹¬ ìš”ì ì„ ë¬¸ì¥ìœ¼ë¡œ ë‚˜ì—´í•˜ì„¸ìš”:
        - í‰ê· , ê·¹ë‹¨ê°’, ì§‘ë‹¨ ê°„ ì°¨ì´, í‘œì¤€í¸ì°¨ê°€ í° í•­ëª©
        - ìš”ì•½ì— ë°˜ë“œì‹œ ë“¤ì–´ê°€ì•¼ í•  ìˆ˜ì¹˜ ê¸°ë°˜ ì •ë³´

        ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
        - 60ëŒ€ëŠ” í‰ê·  4.1ë¡œ ê°€ì¥ ë†’ì€ ê´€ì‹¬ë„ë¥¼ ë³´ì„
        - ì‹¤ì™¸ ì²´ë¥˜ìëŠ” 'ë§¤ìš° ê´€ì‹¬ ìˆë‹¤' ë¹„ìœ¨ì´ 25.9%ë¡œ ê°€ì¥ ë†’ìŒ
        - ê¸°ì €ì§ˆí™˜ì ë³´ìœ  ì—¬ë¶€ì— ë”°ë¼ 'ê´€ì‹¬ ìˆë‹¤' ë¹„ìœ¨ì´ 11% ì°¨ì´ë‚¨
        """)
    )


def get_summary_template():
    return PromptTemplate(
        input_variables=["question_text", "linearized_table", "skeleton", "analysis_results"],
        template=dedent("""
        ë‹¹ì‹ ì€ ê°ê´€ì ì¸ í†µê³„ ê¸°ë°˜ ìš”ì•½ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ëŠ” ì„œìš¸ì‹œ ì‹œë¯¼ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì„¤ë¬¸ì¡°ì‚¬ì˜ ë°ì´í„°ì…ë‹ˆë‹¤.

        â“ [ì§ˆë¬¸]
        {question_text}

        ğŸ“Š [í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ)]
        {linearized_table}

        ğŸ“ˆ [ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ (ëŒ€ë¶„ë¥˜ë³„ í•­ëª©ë³„ max/min ë° ë¶„ì‚° ë“±)]
        {analysis_results}

        ğŸ“ [ì°¸ê³ ìš© ìŠ¤ì¼ˆë ˆí†¤ ìš”ì ë“¤]
        ë‹¤ìŒì€ í†µê³„ì ìœ¼ë¡œ ì£¼ëª©í•  ë§Œí•œ ì‘ë‹µ ê²½í–¥ì„ ìš”ì•½í•œ ì˜ˆì‹œì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í¬í•¨í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, ìš”ì•½ ì‘ì„±ì— ì°¸ê³ í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.
        {skeleton}

        ğŸ§  Chain of Thought ì¶”ë¡  ìˆœì„œ:
        1. ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë°˜ì˜í•˜ì—¬ í‘œì™€ ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ì—ì„œ ì˜ë¯¸ ìˆëŠ” íŒ¨í„´ì„ ì‹ë³„í•©ë‹ˆë‹¤.
        2. í‰ê· , ê·¹ë‹¨ê°’, í‘œì¤€í¸ì°¨ ë“± ìˆ˜ì¹˜ ê¸°ë°˜ ì°¨ì´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤.
        3. ì°¸ê³  ìš”ì ê³¼ ë¹„êµí•˜ì—¬ ëˆ„ë½ëœ ì¤‘ìš”í•œ í†µê³„ì  íŠ¹ì§•ì´ ìˆë‹¤ë©´ ë°˜ì˜í•©ë‹ˆë‹¤.

        ğŸ“ ì‘ì„± ì¡°ê±´:
        - ë°˜ë“œì‹œ ìˆ˜ì¹˜ ê¸°ë°˜ ê·¼ê±°ë§Œì„ ë°”íƒ•ìœ¼ë¡œ í•´ì„í•˜ë©°, ì™¸ë¶€ ë°°ê²½ì§€ì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
        - ëª¨ë“  ì†Œë¶„ë¥˜ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ˆì„¸ìš”. ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì´ëŠ” í•­ëª© ìœ„ì£¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        - ë¬¸ì¥ì€ **ê°ê´€ì ì´ê³  ëª…í™•í•˜ê²Œ**, **ì„œìˆ í˜• ë¬¸ë‹¨ 1~2ê°œ**ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
        - ì œëª©ì€ ì“°ì§€ ë§ˆì‹œê³ , ìš”ì•½ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        """)
    )

def get_review_template():
    return PromptTemplate(
        input_variables=["question_text", "linearized_table", "summary"],
        template=dedent("""
        ë‹¹ì‹ ì€ í†µê³„ ê¸°ë°˜ ë³´ê³ ì„œë¥¼ ê²€í† í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì„¤ë¬¸ ì§ˆë¬¸ê³¼ ê·¸ì— ëŒ€í•œ ìš”ì•½ì„ ê²€í† í•˜ê³ , ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€ ë° ê°œì„  ì œì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.

        â“ [ì§ˆë¬¸]
        {question_text}
                        
        ğŸ“Š [í‘œ ë°ì´í„° (ì„ í˜•í™”ëœ í˜•íƒœ)]
        {linearized_table}

        ğŸ“ [ì´ˆì•ˆ ìš”ì•½]
        {summary}

        âœ… ê²€í†  ê¸°ì¤€:
        1. ìš”ì•½ì´ ì§ˆë¬¸ì˜ ì˜ë„ì™€ ê´€ë ¨ëœ í•µì‹¬ ì •ë³´ë¥¼ ì¶©ë¶„íˆ ë‹´ê³  ìˆëŠ”ê°€?
        2. ìˆ˜ì¹˜ ê¸°ë°˜ í†µê³„ ì •ë³´ê°€ ì ì ˆíˆ ë°˜ì˜ë˜ì–´ ìˆëŠ”ê°€?
        3. ë¬¸ì¥ì´ ê°„ê²°í•˜ê³ , ì¤‘ë³µ í‘œí˜„ ì—†ì´ ëª…í™•í•œê°€?
        4. ë¶ˆí•„ìš”í•œ ë°˜ë³µ, ë¶€ì •í™•í•œ í•´ì„, ì£¼ê´€ì  í‘œí˜„ì´ ì—†ëŠ”ê°€?

        ğŸ” ì¶œë ¥ í˜•ì‹:
        - ê°„ë‹¨í•œ í‰ê°€ (ì¢‹ì€ ì , ê°œì„ ì )
        - í•„ìš”ì‹œ ë‹¤ë“¬ì€ ë²„ì „ ì œì•ˆ (ì„ íƒ ì‚¬í•­)
        """)
    )

def get_final_report_template():
    return PromptTemplate(
        input_variables=["question_text", "summary", "review"],
        template=dedent("""
        ë‹¹ì‹ ì€ í†µê³„ ê¸°ë°˜ ë³´ê³ ì„œë¥¼ ìµœì¢… ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

        ì•„ë˜ëŠ” ì‘ì„±ëœ ìš”ì•½ê³¼ ì´ì— ëŒ€í•œ ë¦¬ë·° í”¼ë“œë°±ì…ë‹ˆë‹¤.
        ë¦¬ë·°ë¥¼ ì°¸ê³ í•˜ì—¬ ìµœì¢… ìš”ì•½(report)ì„ ë³´ì™„/ìˆ˜ì •ëœ í˜•íƒœë¡œ ìƒˆë¡œ ì‘ì„±í•˜ì„¸ìš”.

        â“ [ì§ˆë¬¸]
        {question_text}

        ğŸ“ [ì´ˆì•ˆ ìš”ì•½]
        {summary}

        ğŸ§ [ë¦¬ë·° í”¼ë“œë°±]
        {review}

        ğŸ“Œ ì‘ì„± ì¡°ê±´:
        - ë¦¬ë·°ì—ì„œ ì§€ì ëœ ê°œì„ ì‚¬í•­ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”.
        - ìˆ˜ì¹˜ ê¸°ë°˜ í†µê³„ë¥¼ ìœ ì§€í•˜ê³ , ë” ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        - ë¬¸ì¥ì€ ì„œìˆ í˜• ë¬¸ë‹¨ 1~2ê°œë¡œ êµ¬ì„±í•˜ê³ , ì œëª© ì—†ì´ ìš”ì•½ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        """)
    )

def run_summary_pipeline(table, question_text, linearized_table, analysis_results, model_name="llama-3.1-8B-instrcut:latest"):
    llm_main = ChatOllama(model=model_name, temperature=0.3)
    llm_reviewer = ChatOpenAI(model="gpt-4o", temperature=0.2)

    skeleton_chain = LLMChain(llm=llm_main, prompt=get_skeleton_template(), output_key="skeleton")
    summary_chain = LLMChain(llm=llm_main, prompt=get_summary_template(), output_key="summary")
    review_chain  = LLMChain(llm=llm_reviewer, prompt=get_review_template(), output_key="review")
    final_report_chain = LLMChain(llm=llm_reviewer, prompt=get_final_report_template(), output_key="final_report")

    full_chain = SequentialChain(
        chains=[skeleton_chain, summary_chain, review_chain, final_report_chain],
        input_variables=["question_text", "linearized_table", "analysis_results"],
        output_variables=["skeleton", "summary", "review", "final_report"],
        verbose=True
    )

    return full_chain.invoke({
        "question_text": question_text,
        "linearized_table": linearized_table,
        "analysis_results": analysis_results
    })


def main():
    file_path = "í†µê³„í‘œ_ìˆ˜ì •_ì„œìš¸ì‹œ ëŒ€ê¸°í™˜ê²½ ì‹œë¯¼ì¸ì‹ ì¡°ì‚¬_250421(ì‘ì—…ìš©).xlsx"

    table, question_text, key = get_user_selected_table(file_path)
    linearized = linearize_row_wise(table)
    analysis = numeric_analysis(table)

    result = run_summary_pipeline(table, question_text, linearized, analysis)

    print("\nğŸ”‘ [ìŠ¤ì¼ˆë ˆí†¤ ìš”ì ]")
    print(result["skeleton"])
    print("-" * 20)

    print("\nğŸ”‘ [ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼]")
    print(analysis)
    print("-" * 20)

    print(f"\nğŸ“ [ìµœì¢… ìš”ì•½ for {key}]")
    print(result["summary"])
    print("-" * 20)

    print("\nğŸ§  [GPT-4o ë¦¬ë·°]")
    print(result["review"])
    print("-" * 20)

    print(f"\nğŸ“„ [ìµœì¢… Report (ìˆ˜ì • ì™„ë£Œ)]")
    print(result["final_report"])


if __name__ == "__main__":
    main()